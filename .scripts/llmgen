#! /usr/bin/env python3

import argparse
import os
import json
import time
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed

# =======================
# Config
# =======================
SERVER_ADDR = "https://api.deepseek.com/chat/completions"
API_KEY = "sk-25708c5d4945471784a11ebfc6fa64b7"
MODEL_NAME = "deepseek-chat"

# SERVER_ADDR = "http://10.178.29.70:80/v2/chat/completions"
# API_KEY = "bce-v3/ALTAK-seG05tfjoB4V83dl1I60P/df902ea834c2c21559ac5feb3a5720dc175c9733"
# MODEL_NAME = "aiak_bzz2_deepseek_v32_rd_test3"

CONFIG_DIR = os.path.expanduser("~/.scripts/prompts")

MAX_RETRIES = 3
API_TIMEOUT = 600
VERIFY_SSL = True

# =======================
# Helpers
# =======================
def load_prompt(prompt_name):
    prompt_file = os.path.join(CONFIG_DIR, f"{prompt_name}.txt")
    if not os.path.exists(prompt_file):
        raise FileNotFoundError(f"Prompt file {prompt_file} not found")
    with open(prompt_file, 'r', encoding='utf-8') as f:
        return f.read()


def read_file_content(filename):
    with open(filename, 'r', encoding='utf-8') as f:
        return f.read()


def write_result(result, filename, inplace, to_markdown, prompt_name):
    if inplace:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(result)
    elif to_markdown:
        md_path = os.path.splitext(filename)[0] + "-" + prompt_name + ".md"
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(result)
        print(f"üìù Wrote Markdown output to {md_path}")
    else:
        print(f"\n=== Output for {filename} ===\n")
        print(result)


# =======================
# Core HTTP Call
# =======================
def call_llm(prompt, content):
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}",
    }

    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": prompt},
            {"role": "user", "content": content}
        ]
    }

    for attempt in range(1, MAX_RETRIES + 1):
        try:
            response = requests.post(
                SERVER_ADDR,
                headers=headers,
                data=json.dumps(payload),
                timeout=API_TIMEOUT,
                verify=VERIFY_SSL
            )

            response.raise_for_status()
            data = response.json()

            if 'choices' not in data or not data['choices']:
                raise ValueError("Invalid response: no choices")

            return data['choices'][0]['message']['content']

        except Exception as e:
            print(f"‚ö†Ô∏è Attempt {attempt}/{MAX_RETRIES} failed: {e}")
            if attempt < MAX_RETRIES:
                time.sleep(2 * attempt)
            else:
                raise


# =======================
# File Processing
# =======================
def process_file(filename, prompt, index, inplace, to_markdown, prompt_name):
    try:
        content = read_file_content(filename)

        result = call_llm(prompt, content)

        print(f"[{index+1}] ‚úÖ Processed {filename}")
        write_result(result, filename, inplace, to_markdown, prompt_name)
        return index, result, filename

    except Exception as e:
        print(f"[{index+1}] ‚ùå Error processing {filename}: {e}")
        error_result = f"<!-- Error processing {filename}: {e} -->"
        write_result(error_result, filename, inplace, to_markdown, prompt_name)
        return index, error_result, filename


def process_files(filenames, prompt_name, inplace, to_markdown, workers):
    prompt = load_prompt(prompt_name)
    print(f"üìÑ Processing {len(filenames)} file(s) with prompt '{prompt_name}'")

    if inplace:
        print("‚úçÔ∏è In-place mode enabled.")
    if to_markdown:
        print("üìù Markdown output mode enabled.")

    with ThreadPoolExecutor(max_workers=workers) as executor:
        futures = [
            executor.submit(
                process_file,
                filename,
                prompt,
                idx,
                inplace,
                to_markdown,
                prompt_name
            )
            for idx, filename in enumerate(filenames)
        ]

        for future in as_completed(futures):
            future.result()


# =======================
# Main
# =======================
def main():
    parser = argparse.ArgumentParser(
        description="Process files with LLM using configurable prompts",
        allow_abbrev=False
    )
    parser.add_argument('filenames', nargs='+', help='Input file(s)')
    parser.add_argument('--prompt', default='default', help='Prompt name (without .txt)')
    parser.add_argument('--inplace', action='store_true', help='Modify files in place')
    parser.add_argument('--markdown', action='store_true', help='Write output to markdown')
    parser.add_argument('--workers', type=int, default=1, help='Number of workers')

    args = parser.parse_args()

    if not os.path.exists(CONFIG_DIR):
        raise FileNotFoundError(f"Config directory '{CONFIG_DIR}' not found")

    for filename in args.filenames:
        if not os.path.exists(filename):
            raise FileNotFoundError(f"Input file {filename} not found")

    if args.inplace and args.markdown:
        raise ValueError("Cannot use --inplace and --markdown together")

    process_files(
        args.filenames,
        args.prompt,
        args.inplace,
        args.markdown,
        args.workers
    )


if __name__ == '__main__':
    main()

